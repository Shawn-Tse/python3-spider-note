如果想要大规模抓取数据，那么一定会用到分布式爬虫，对于分布式爬虫来说，我们一定需要多台主机，每台主机多个爬虫任务，但是源代码其实只有一份。那么我们需要做的就是将一份代码同时部署到多台主机上来协同运行。

对于 Scrapy 来说，它有一个扩展组件叫做 Scrapyd，我们只需要安装 Scrapyd 即可远程管理 Scrapy 任务，包括部署源码、启动任务、监听任务等操作。另外还有 ScrapydClient 和 ScrapydAPI 来帮助我们更方便地完成部署和监听操作。

另外还有一种部署方式就是 Docker 集群部署，我们只需要将爬虫制作为 Docker 镜像，只要主机安装了 Docker，就可以直接运行爬虫，而无需再去担心环境配置、版本问题。

