# Summary

## Spider-Note

* [Introduction](README.md)

## 1.开发环境配置

* [1.1 python3的安装](1./1.1-python3.md)
  * [1.1.1 windows下的安装](1./1.1.1-windows.md)
  * [1.1.2 Linux下的安装](1./1.1.2-linux.md)
  * 1.1.3 Mac下的安装
* 1.2 请求库的安装
  * 1.2.1 requests的安装
  * 1.2.2 selenium的安装
  * 1.2.3 ChromeDriver的安装
  * 1.2.4 GrckoDriver的安装
  * 1.2.5 aiohttp的安装
* 1.3 解析库的安装
  * 1.3.1 lxml的安装
  * 1.3.2 Beautiful Soup的安装
  * 1.3.3 pyquery的安装
  * 1.3.4 tesserocr的安装
* 1.4 数据库的安装
  * 1.4.1 MySQL的安装
  * 1.4.2 MongoDB的安装
  * 1.4.3 Redis的安装
* 1.5 存储库的安装
  * 1.5.1 PyMySQL的安装
  * 1.5.2 PyMongo的安装
  * 1.5.3 redis-py的安装
  * 1.5.4 RedisDump的安装
* 1.6 Web库的安装
  * 1.6.1 Flask的安装
  * 1.6.2 Tornado的安装
* 1.7 App爬取相关库的安装
  * 1.7.1 Charles的安装
  * 1.7.2 mitmproxy的安装
  * 1.7.3 Appium的安装
* 1.8 爬虫框架的安装
  * 1.8.1 pyspider的安装
  * 1.8.2 Scrapy的安装
  * 1.8.3 Scrapy-Splash的安装
  * 1.8.4 Scrapy-Splash的安装
* 1.9 部署相关库的安装
  * 1.9.1 Docker的安装
  * 1.9.2 Scrapyd的安装
  * 1.9.3 Scrapyd-Client的安装
  * 1.9.4 Scrapyd API的安装
  * 1.9.5 Scrapyrt的安装
  * 1.9.6 Gerapy的安装

## 2.爬虫基础

* 2.1 HTTP 基本原理
  * 2.1.1 URI和URL
  * 2.1.2 超文本
  * 2.1.3 HTTP和HTTPS
  * 2.1.4 HTTP请求过程
  * 2.1.5 请求
  * 2.1.6 响应
* 2.2 网页基础
  * 2.2.1网页的组成
  * 2.2.2 网页的结构
  * 2.2.3 节点树及节点间的关系
  * 2.2.4 选择器
* 2.3 爬虫的基本原理
  * 2.3.1 爬虫概述
  * 2.3.2 能抓怎样的数据
  * 2.3.3 javascript渲染的页面
* 2.4 会话和Cookies
  * 2.4.1 静态网页和动态网页
  * 2.4.2 无状态HTTP
  * 2.4.3 常见误区
* 2.5 代理的基本原理

  * 2.5.1 基本原理

  * 2.5.2 代理的作用

  * 2.5.3 爬虫代理

  * 2.5.4 代理分类

  * 2.5.5 常见代理设置

## 3. 基本库的使用

* 3.1 使用urllib
  * 3.1.1 发送请求
  * 3.1.2 处理异常
  * 3.1.3 解析链接
  * 3.1.4 分析Robots协议
* 3.2 使用requests
  * 3.2.1 基本用法
  * 3.2.2 高级用法
* 3.3 正则表达式
* 3.4 抓取猫眼电影排行

## 4.解析库的使用

* 4.1 使用xpath
* 4.2 使用Beautiful Soup
* 4.3 使用pyquery

## 5.数据存储

* 5.1 文件存储
  * 5.1.1 TXT 文件存储
  * 5.1.2 JSON文件存储
  * 5.1.3 CSV文件存储
* 5.2 关系型数据库存储
  * 5.2.1 MySQL的存储
* 5.3 非关系数据库存储
  * 5.3.1 MongoDB存储
  * 5.3.2 Redis存储

## 6.Ajax数据爬取

* 6.1 什么是Ajax
* 6.2 Ajax分析方法
* 6.3 Ajax结果提取
* 6.4 分析Ajax爬取今日头条街拍美图

## 7.动态渲染页面爬取



