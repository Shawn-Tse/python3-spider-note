[Python3网络爬虫开发实战](https://legacy.gitbook.com/book/germey/python3webspider)

* 
* [前言](https://germey.gitbooks.io/python3webspider/content/)
* [目录](https://germey.gitbooks.io/python3webspider/content/0-目录.html)
* [第一章 开发环境配置](https://germey.gitbooks.io/python3webspider/content/1-开发环境配置.html)
* [1.1-Python3的安装](https://germey.gitbooks.io/python3webspider/content/1.1-Python3的安装.html)
* [1.2-请求库的安装](https://germey.gitbooks.io/python3webspider/content/1.2-请求库的安装.html)
* [1.2.1-Requests的安装](https://germey.gitbooks.io/python3webspider/content/1.2.1-Requests的安装.html)
* [1.2.2-Selenium的安装](https://germey.gitbooks.io/python3webspider/content/1.2.2-Selenium的安装.html)
* [1.2.3-ChromeDriver的安装](https://germey.gitbooks.io/python3webspider/content/1.2.3-ChromeDriver的安装.html)
* [1.2.4-GeckoDriver的安装](https://germey.gitbooks.io/python3webspider/content/1.2.4-GeckoDriver的安装.html)
* [1.2.5-PhantomJS的安装](https://germey.gitbooks.io/python3webspider/content/1.2.5-PhantomJS的安装.html)
* [1.2.6-Aiohttp的安装](https://germey.gitbooks.io/python3webspider/content/1.2.6-Aiohttp的安装.html)
* [1.3-解析库的安装](https://germey.gitbooks.io/python3webspider/content/1.3-解析库的安装.html)
* [1.3.1-LXML的安装](https://germey.gitbooks.io/python3webspider/content/1.3.1-LXML的安装.html)
* [1.3.2-BeautifulSoup的安装](https://germey.gitbooks.io/python3webspider/content/1.3.2-BeautifulSoup的安装.html)
* [1.3.3-PyQuery的安装](https://germey.gitbooks.io/python3webspider/content/1.3.3-PyQuery的安装.html)
* [1.3.4-Tesserocr的安装](https://germey.gitbooks.io/python3webspider/content/1.3.4-Tesserocr的安装.html)
* [1.4-数据库的安装](https://germey.gitbooks.io/python3webspider/content/1.4-数据库的安装.html)
* [1.4.1-MySQL的安装](https://germey.gitbooks.io/python3webspider/content/1.4.1-MySQL的安装.html)
* [1.4.2-MongoDB的安装](https://germey.gitbooks.io/python3webspider/content/1.4.2-MongoDB的安装.html)
* [1.4.3-Redis的安装](https://germey.gitbooks.io/python3webspider/content/1.4.3-Redis的安装.html)
* [1.5-存储库的安装](https://germey.gitbooks.io/python3webspider/content/1.5-存储库的安装.html)
* [1.5.1-PyMySQL的安装](https://germey.gitbooks.io/python3webspider/content/1.5.1-PyMySQL的安装.html)
* [1.5.2-PyMongo的安装](https://germey.gitbooks.io/python3webspider/content/1.5.2-PyMongo的安装.html)
* [1.5.3-RedisPy的安装](https://germey.gitbooks.io/python3webspider/content/1.5.3-RedisPy的安装.html)
* [1.5.4-RedisDump的安装](https://germey.gitbooks.io/python3webspider/content/1.5.4-RedisDump的安装.html)
* [1.6-Web库的安装](https://germey.gitbooks.io/python3webspider/content/1.6-Web库的安装.html)
* [1.6.1-Flask的安装](https://germey.gitbooks.io/python3webspider/content/1.6.1-Flask的安装.html)
* [1.6.2-Tornado的安装](https://germey.gitbooks.io/python3webspider/content/1.6.2-Tornado的安装.html)
* [1.7-APP爬取相关库的安装](https://germey.gitbooks.io/python3webspider/content/1.7-APP爬取相关库的安装.html)
* [1.7.1-Charles的安装](https://germey.gitbooks.io/python3webspider/content/1.7.1-Charles的安装.html)
* [1.7.2-MitmProxy的安装](https://germey.gitbooks.io/python3webspider/content/1.7.2-MitmProxy的安装.html)
* [1.7.3-Appium的安装](https://germey.gitbooks.io/python3webspider/content/1.7.3-Appium的安装.html)
* [1.8-爬虫框架的安装](https://germey.gitbooks.io/python3webspider/content/1.8-爬虫框架的安装.html)
* [1.8.1-PySpider的安装](https://germey.gitbooks.io/python3webspider/content/1.8.1-PySpider的安装.html)
* [1.8.2-Scrapy的安装](https://germey.gitbooks.io/python3webspider/content/1.8.2-Scrapy的安装.html)
* [1.8.3-ScrapySplash的安装](https://germey.gitbooks.io/python3webspider/content/1.8.3-ScrapySplash的安装.html)
* [1.8.4-ScrapyRedis的安装](https://germey.gitbooks.io/python3webspider/content/1.8.4-ScrapyRedis的安装.html)
* [1.9-部署相关库的安装](https://germey.gitbooks.io/python3webspider/content/1.9-部署相关库的安装.html)
* [1.9.1-Docker的安装](https://germey.gitbooks.io/python3webspider/content/1.9.1-Docker的安装.html)
* [1.9.2-Scrapyd的安装](https://germey.gitbooks.io/python3webspider/content/1.9.2-Scrapyd的安装.html)
* [1.9.3-ScrapydClient的安装](https://germey.gitbooks.io/python3webspider/content/1.9.3-ScrapydClient的安装.html)
* [1.9.4-ScrapydAPI的安装](https://germey.gitbooks.io/python3webspider/content/1.9.4-ScrapydAPI的安装.html)
* [1.9.5-Scrapyrt的安装](https://germey.gitbooks.io/python3webspider/content/1.9.5-Scrapyrt的安装.html)
* [1.9.6-Gerapy的安装](https://germey.gitbooks.io/python3webspider/content/1.9.6-Gerapy的安装.html)
* [第二章 爬虫基础](https://germey.gitbooks.io/python3webspider/content/2-爬虫基础.html)
* [2.1-HTTP基本原理](https://germey.gitbooks.io/python3webspider/content/2.1-HTTP基本原理.html)
* [2.2-Web网页基础](https://germey.gitbooks.io/python3webspider/content/2.2-Web网页基础.html)
* [2.3-爬虫基本原理](https://germey.gitbooks.io/python3webspider/content/2.3-爬虫基本原理.html)
* [2.4-Session和Cookies](https://germey.gitbooks.io/python3webspider/content/2.4-Session和Cookies.html)
* [2.5-代理基本原理](https://germey.gitbooks.io/python3webspider/content/2.5-代理基本原理.html)
* [第三章 基本库的使用](https://germey.gitbooks.io/python3webspider/content/3-基本库的使用.html)
* [3.1-使用Urllib](https://germey.gitbooks.io/python3webspider/content/3.1-使用Urllib.html)
* [3.1.1-发送请求](https://germey.gitbooks.io/python3webspider/content/3.1.1-发送请求.html)
* [3.1.2-处理异常](https://germey.gitbooks.io/python3webspider/content/3.1.2-处理异常.html)
* [3.1.3-解析链接](https://germey.gitbooks.io/python3webspider/content/3.1.3-解析链接.html)
* [3.1.4-分析Robots协议](https://germey.gitbooks.io/python3webspider/content/3.1.4-分析Robots协议.html)
* [3.2-使用Requests](https://germey.gitbooks.io/python3webspider/content/3.2-使用Requests.html)
* [3.2.1-基本使用](https://germey.gitbooks.io/python3webspider/content/3.2.1-基本使用.html)
* [3.2.3-高级用法](https://germey.gitbooks.io/python3webspider/content/3.2.3-高级用法.html)
* [3.3-正则表达式](https://germey.gitbooks.io/python3webspider/content/3.3-正则表达式.html)
* [3.4-Requests与正则表达式爬取猫眼电影排行](https://germey.gitbooks.io/python3webspider/content/3.4-Requests与正则表达式爬取猫眼电影排行.html)
* [第四章 解析库的使用](https://germey.gitbooks.io/python3webspider/content/4-解析库的使用.html)
* [4.1-XPath的使用](https://germey.gitbooks.io/python3webspider/content/4.1-XPath的使用.html)
* [4.2-BeautifulSoup的使用](https://germey.gitbooks.io/python3webspider/content/4.2-BeautifulSoup的使用.html)
* [4.3-PyQuery的使用](https://germey.gitbooks.io/python3webspider/content/4.3-PyQuery的使用.html)
* [第五章 数据存储](https://germey.gitbooks.io/python3webspider/content/5-数据存储.html)
* [5.1-文件存储](https://germey.gitbooks.io/python3webspider/content/5.1-文件存储.html)
* [5.1.1-TXT文本存储](https://germey.gitbooks.io/python3webspider/content/5.1.1-TXT文本存储.html)
* [5.1.2-Json文件存储](https://germey.gitbooks.io/python3webspider/content/5.1.2-Json文件存储.html)
* [5.1.3-CSV文件存储](https://germey.gitbooks.io/python3webspider/content/5.1.3-CSV文件存储.html)
* [5.2-关系型数据库存储](https://germey.gitbooks.io/python3webspider/content/5.2-关系型数据库存储.html)
* [5.2.1-MySQL存储](https://germey.gitbooks.io/python3webspider/content/5.2.1-MySQL存储.html)
* [5.3-非关系型数据库存储](https://germey.gitbooks.io/python3webspider/content/5.3-非关系型数据库存储.html)
* [5.3.1-MongoDB存储](https://germey.gitbooks.io/python3webspider/content/5.3.1-MongoDB存储.html)
* [5.3.2-Redis存储](https://germey.gitbooks.io/python3webspider/content/5.3.2-Redis存储.html)
* [第六章 Ajax数据爬取](https://germey.gitbooks.io/python3webspider/content/6-Ajax数据爬取.html)
* [6.1-什么是Ajax](https://germey.gitbooks.io/python3webspider/content/6.1-什么是Ajax.html)
* [6.2-Ajax分析方法](https://germey.gitbooks.io/python3webspider/content/6.2-Ajax分析方法.html)
* [6.3-Ajax结果提取](https://germey.gitbooks.io/python3webspider/content/6.3-Ajax结果提取.html)
* [6.4-分析Ajax爬取今日头条街拍美图](https://germey.gitbooks.io/python3webspider/content/6.4-分析Ajax爬取今日头条街拍美图.html)
* [第七章 动态渲染页面抓取](https://germey.gitbooks.io/python3webspider/content/7-动态渲染页面抓取.html)
* [7.1-Selenium的使用](https://germey.gitbooks.io/python3webspider/content/7.1-Selenium的使用.html)
* [7.2-Splash的使用](https://germey.gitbooks.io/python3webspider/content/7.2-Splash的使用.html)
* [7.3-Splash负载均衡配置](https://germey.gitbooks.io/python3webspider/content/7.3-Splash负载均衡配置.html)
* [7.4-使用Selenium爬取淘宝商品](https://germey.gitbooks.io/python3webspider/content/7.4-使用Selenium爬取淘宝商品.html)
* [第八章 验证码的识别](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [8.1-图形验证码的识别](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [8.2-极验滑动验证码识别](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [8.3-点触验证码识别](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [8.4-微博宫格验证码识别](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [第九章 代理的使用](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [9.1-代理的设置](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [9.2-代理池的维护](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [9.3-付费代理的使用](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [9.4-ADSL代理的使用](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [9.5-使用代理爬取微信公众号文章](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [第十章 模拟登录](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [10.1-模拟登录并爬取GitHub](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [10.2-Cookies池的搭建](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [第十一章 APP的爬取](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [11.1-Charles的使用](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [11.2-MitmProxy的使用](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [11.3-MitmDump爬取得到APP电子书信息](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [11.4-Appium的使用](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [11.5-Appium爬取微信朋友圈](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [11.6-Appium+MitmProxy爬取京东商品评论](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [第十二章 PySpider框架的使用](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [12.1-PySpider框架介绍](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [12.2-PySpider基本使用](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [12.3-PySpider用法详解](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [第十三章 Scrapy框架的使用](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [13.1-Scrapy框架介绍](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [13.2-Scrapy入门](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [13.3-Selector的用法](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [13.4-Spider的用法](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [13.5-Downloader Middleware的用法](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [13.6-Spider Middleware的用法](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [13.7-Item Pipeline的用法](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [13.8-Scrapy对接Selenium](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [13.9-Scrapy对接Splash](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [13.10-Scrapy通用爬虫](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [13.11-Scrapyrt的使用](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [13.12-Scrapy对接Docker](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [13.13-Scrapy爬取新浪微博](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [第十四章 分布式爬虫](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [14.1-分布式爬虫理念](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [14.2-ScrapyRedis源码解析](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [14.3-Scrapy分布式实现](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [14.4-BloomFilter的对接](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [第十五章 分布式爬虫的部署](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [15.1-Scrapyd分布式部署](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [15.2-ScrapydClient的使用](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [15.3-Scrapyd对接Docker](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [15.4-Scrapyd批量部署](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* [15.5-Gerapy分布式管理](https://germey.gitbooks.io/python3webspider/content/VIP.html)
* 
* [本書使用 GitBook 釋出](https://www.gitbook.com/)

## 1.4.2 MongoDB安装 {#142-mongodb安装}

MongoDB 是由 C++ 语言编写的非关系型数据库，是一个基于分布式文件存储的开源数据库系统，其内容存储形式类似 Json 对象，它的字段值可以包含其他文档，数组及文档数组，非常灵活。

MongoDB 支持多种平台，包括 Windows、Linux、Mac OS、Solaris 等，在其官方网站均可找到对应的安装包，[https://www.mongodb.com/download-center](https://www.mongodb.com/download-center)

本节我们来看下它的安装过程。+

### 1. 相关链接 {#1-相关链接}

* 官方网站：
  [https://www.mongodb.com](https://www.mongodb.com/)
* 官方文档：
  [https://docs.mongodb.com](https://docs.mongodb.com/)
* GitHub：
  [https://github.com/mongodb](https://github.com/mongodb)
* 中文教程：
  [http://www.runoob.com/mongodb/mongodb-tutorial.html](http://www.runoob.com/mongodb/mongodb-tutorial.html)

### 2. Windows下的安装 {#2-windows下的安装}

直接在官网下载安装包即可，链接为：[https://www.mongodb.com/download-center\#community](https://www.mongodb.com/download-center#community)，页面如图 1-29 所示：

![](https://germey.gitbooks.io/python3webspider/content/assets/1-29.jpg)

图 1-29 下载页面

直接点击 Download 下载 msi 安装包即可。

下载完成之后双击开始安装，指定 MongoDB 的安装路径，例如在此处我指定安装路径为 C:\MongoDB\Server\3.4，当然路径可以自行选择，如图 1-30 所示：

![](https://germey.gitbooks.io/python3webspider/content/assets/1-30.jpg)

图 1-30 安装页面

点击下一步执行安装即可。

安装成功之后，进入 MongoDB 的安装目录，在此处所在路径是 C:\MongoDB\Server\3.4，在 bin 目录下新建同级目录 data，如图 1-31 所示：

![](https://germey.gitbooks.io/python3webspider/content/assets/1-31.jpg)

图 1-31 新建 data 目录结果

然后进入 data 文件夹新建子文件夹 db，作为数据目录存储的文件夹，如图 1-32 所示：

![](https://germey.gitbooks.io/python3webspider/content/assets/1-32.jpg)

图 1-32 新建 db 目录结果

之后打开命令行，进入 MongoDB 安装目录的 bin 目录下，运行 MongoDB 服务：

```
mongod --dbpath "C:\MongoDB\Server\3.4\data\db"
```

请记得将此处的路径替换成你的主机 MongoDB 安装路径。

运行之后会出现一些输出信息，如图 1-33 所示：

![](https://germey.gitbooks.io/python3webspider/content/assets/1-33.jpg)

图 1-33 运行结果

这样我们就已经将 MongoDB 服务启动了。

但是这样如果我们想一直使用 MongoDB 就不能关闭此命令行，如果意外关闭或重启 MongoDB 服务就不能使用了，这显然不是我们想要的，所以接下来我们还需将 MongoDB 配置成系统服务。

首先我们要以管理员模式运行命令行，注意此处一定要是管理员模式运行，否则可能配置失败，如图 1-34 所示：

![](https://germey.gitbooks.io/python3webspider/content/assets/1-34.jpg)

图 1-34 管理员模式

开始菜单搜索 cmd，找到命令行，然后右键以管理员身份运行即可。

随后新建一个日志文件，在 bin 目录同级目录新建 logs 文件夹，进入之后新建一个 mongodb.log 文件，用于保存 MongoDB 运行的日志，如图 1-35 所示。

![](https://germey.gitbooks.io/python3webspider/content/assets/1-35.jpg)

图 1-35 新建 mongodb.log 结果

在命令行下输入如下内容：

```
mongod --bind_ip 0.0.0.0 --logpath "C:\MongoDB\Server\3.4\logs\mongodb.log" --logappend --dbpath "C:\MongoDB\Server\3.4\data\db" --port 27017 --serviceName "MongoDB" --serviceDisplayName "MongoDB" --install
```

这里的意思是绑定 IP 为 0.0.0.0，即任意 IP 均可访问，指定日志路径、数据库路径、端口，指定服务名称，注意这里依然需要把路径替换成你的 MongoDB 安装路径，运行此命令后即可安装服务，运行结果如图 1-36 所示：

![](https://germey.gitbooks.io/python3webspider/content/assets/1-36.jpg)

图 1-36 运行结果

如果没有出现错误提示，则证明 MongoDB 服务已经安装成功。

可以在服务管理页面查看到系统服务，如图 1-37 所示：

![](https://germey.gitbooks.io/python3webspider/content/assets/2017-06-06-11-52-51.jpg)

图 1-37 系统服务页面

可以设置它的开机启动方式，如自动启动或手动启动等。这样我们就可以非常方便地管理 MongoDB 服务了。

启动服务之后我们在命令行下就可以利用 mongo 命令进入 MongoDB 命令交互环境了，如图 1-38 所示：

![](https://germey.gitbooks.io/python3webspider/content/assets/1-38.jpg)

图 1-38 命令行模式

这样 Windows 下 MongoDB 配置就完成了。

### 3. Linux下的安装 {#3-linux下的安装}

在这里以 MongoDB 3.4 为例说明 MongoDB 的安装过程。

#### Ubuntu {#ubuntu}

首先导入 MongoDB 的 GPG Key：

```
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 0C49F3730359A14518585931BC711F9BA15703C6
```

随后创建 apt-get 源列表，各个系统版本对应的命令如下：

* Ubuntu 12.04

```
echo "deb [ arch=amd64 ] http://repo.mongodb.org/apt/ubuntu precise/mongodb-org/3.4 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.list
```

* Ubuntu 14.04

```
echo "deb [ arch=amd64 ] http://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.4 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.list
```

* Ubuntu 16.04

```
echo "deb [ arch=amd64,arm64 ] http://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.4 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.list
```

随后更新 apt-get 源：

```
sudo apt-get update
```

之后安装 MongoDB 即可：

```
sudo apt-get install -y mongodb-org
```

安装完成之后运行 MongoDB，命令如下：

```
mongod --port 27017 --dbpath /data/db
```

运行命令之后 MongoDB 就在 27017 端口上运行了，数据文件会保存在 /data/db 路径下。

一般我们在 Linux 上配置 MongoDB 都是为了远程连接使用的，所以在这里还需要配置一下 MongoDB 的远程连接和用户名密码：

接着我们进入到 MongoDB 命令行：

```
mongo --port 27017
```

现在我们就已经进入到 MongoDB 的命令行交互模式下了，在此模式下运行如下命令：

```
>use admin
switched to db admin

>db.createUser({user: 'admin', pwd: 'admin123', roles: [{role: 'root', db: 'admin'}]})
Successfully added user: {
        "user" : "admin",
        "roles" : [
                {
                        "role" : "root",
                        "db" : "admin"
                }
        ]
}
```

这样我们就创建了一个用户名为 admin，密码为 admin123 的用户，赋予最高权限。

随后需要修改 MongoDB 的配置文件，

执行如下命令：

```
sudo vi /etc/mongod.conf
```

修改 net 部分为：

```
net:
  port: 27017
  bindIp: 0.0.0.0
```

这样配置后 MongoDB 可被远程访问。

另外还需要添加如下权限认证配置，直接添加如下内容到配置文件：

```
security:
 authorization: enabled
```

配置完成之后我们需要重新启动 MongoDB 服务，命令如下：

```
sudo service mongod restart
```

这样远程连接和权限认证就配置完成了。

#### CentOS、RedHat {#centos、redhat}

首先添加 MongoDB 源：

```
sudo vi /etc/yum.repos.d/mongodb-org.repo
```

修改为如下内容保存：

```
[mongodb-org-3.4]
name=MongoDB Repository
baseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.4/x86_64/
gpgcheck=1
enabled=1
gpgkey=https://www.mongodb.org/static/pgp/server-3.4.asc
```

然后执行 yum 命令安装：

```
sudo yum install mongodb-org
```

启动 MongoDB 服务：

```
sudo systemctl start mongod
```

停止和重新加载 MongoDB 服务：

```
sudo systemctl stop mongod
sudo systemctl reload mongod
```

有关远程连接和认证配置可以参考上文，方式是相同的。

更多 Linux 发行版的 MongoDB 安装方式可以参考官方文档：[https://docs.mongodb.com/manual/administration/install-on-linux/](https://docs.mongodb.com/manual/administration/install-on-linux/)。

### 4. Mac下的安装 {#4-mac下的安装}

推荐使用 Homebrew 安装，执行 brew 命令即可：

```
brew install mongodb
```

然后创建一个新文件夹 /data/db，用于存放 MongoDB 数据。

启动 MongoDB 服务：

```
brew services start mongodb
sudo mongod
```

这样就启动了 MongoDB 服务。

停止、重启 MongoDB 服务的命令：

```
brew services stop mongodb
brew services restart mongodb
```

### 5. 可视化工具 {#5-可视化工具}

RoboMongo/Robo 3T，官方网站：[https://robomongo.org/](https://robomongo.org/)，下载链接：[https://robomongo.org/download](https://robomongo.org/download)。

Studio 3T，官方网站：[https://studio3t.com](https://studio3t.com/)，下载链接：[https://studio3t.com/download/](https://studio3t.com/download/)。

